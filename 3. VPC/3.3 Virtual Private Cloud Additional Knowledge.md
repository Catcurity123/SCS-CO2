#### A. SSH Agent Forwarding
(+) We initially created a key pair when establishing the Bastion host, we keep the private key locally, and the host keeps the public key, when we make a connection to the Bastion host, we need to use the private key to prove to the bastion host that we are authorized entity.
(+) After that, we want to go to Private subnet, the host on private subnet do the same thing, it asks the Bastion host to prove itself, however, the bastion host does not have the private key, therefore, the access is denied.
(+) We can fix this by copying the private key onto the bastion host, but this is an anti-pattern because we dont want our private key to be everywhere and this is not scalable.
![[Pasted image 20240108134318.png]]

(+) The solution for this is using SSH Agent Forwarding.
![[Pasted image 20240108134809.png]]

(+) In this solution, we first add the private key as an `identity` into the `ssh-agent service`. We then connect to the Bastion host with the `-A` property to inform that whenever other hosts ask Bastion to identify its identity, the Bastion can forward that request to the `ssh-agent service`.
(+) When the Bastion host attempts to conenct to the Private Subnet, the PV ask BH to identify itself, BH then forward that request to the `ssh-agent service` and as the `ssh-agen service` has our `private key` added to its identity, the authentication process will be done and the access right is granted. Note that at no time does the private key leaves the client machine, the request is forwarded and verified at the client machine.
![[Pasted image 20240108140942.png]]

(+) Note that after adding our identity to the `ssh-agent service` we dont need to provide the private subnet with our private key anymore as the request is forwarded from the bastion to the ssh-agent and handled by the `ssh-agent service`.
(+) In the above example, although we successfully connect to the private instance from the bastion, the private instance still doesnot have conenction to the internet, as we did not create a NAT Gateway.

(+) To do this, we need to create a NAT gateway (for each AZ if we want `a full VPC-resilient NATGW architecture`) and assign it to the correct subnet. After that we will need to create a Route Table for the private subnet to be routed to the NATGW, and assign the route table to every subnets that needs connection to the NATGW.
![[Pasted image 20240108143046.png]]

==> The destination of the least specific IP for this route is `the NAT` meaning that whenever we perform ICMP to IPs that is not in the route table it will be redirected to the NAT, and the NAT will handle the rest.
![[Pasted image 20240108143515.png]]
==> The NATGW has a public IPv4 which will be used for connecting to the internet via the IGW.

![[Pasted image 20240108143256.png]]
==> The route table is associated with subnets that is private and needs connection to the internet (we can discard the db if we dont want db to connect to the internet).

![[Pasted image 20240108143624.png]]
==> With that we successfully implemented this architecture

`Note`:
(+) When we need to clean up the environment, as we delete the VPC, it said that Instances are running, Interfaces is running ,and NAT Gateway is running:
	(-) Instances can be terminated
	(-) Interfaces are for each instances and NATGWs that we allocated, so we needs to delete the NATGWs and terminated instances
	(-) NATGWs can be deleted, however, as NATGWs is attached with EIP, deleting the NATGWs does not mean that the EIPs will also be released, so we also needs to release the EIPs as EIPs is associated with an interfaces.
	==> Once we do that we can delete the VPCs.